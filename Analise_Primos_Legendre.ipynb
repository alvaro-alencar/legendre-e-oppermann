#!/usr/bin/env python3
"""
ğŸ† TESTE MASSIVO: LEGENDRE + OPPERMANN atÃ© n=1,000,000

Este script testa simultaneamente:
- Conjectura de Legendre: âˆƒ primo em (nÂ², (n+1)Â²)
- Conjectura de Oppermann: âˆƒ primos em TODAS as 3 sub-regiÃµes

OtimizaÃ§Ãµes:
- Numba JIT para cÃ¡lculos rÃ¡pidos
- Cache de zeros da zeta
- Checkpoint automÃ¡tico a cada 100 iteraÃ§Ãµes
- Estimativa de tempo restante em tempo real
"""

import numpy as np
from numba import jit
import time
from tqdm import tqdm
import pickle
import matplotlib.pyplot as plt
import mpmath
from sympy import primepi
import json
from datetime import datetime
import os

# ============================================================
# CONFIGURAÃ‡Ã•ES GLOBAIS
# ============================================================

CONFIG = {
    'N_START': 10_000,
    'N_END': 1_000_000,
    'N_STEP': 10_000,  # Testar a cada 10k para velocidade
    'NUM_ZEROS': 500,
    'CHECKPOINT_INTERVAL': 100,
    'OUTPUT_DIR': 'results_1M',
    'CACHE_FILE': 'gammas_500_cache.npy'
}

print("=" * 70)
print("ğŸš€ TESTE MASSIVO: LEGENDRE + OPPERMANN atÃ© n=1,000,000")
print("=" * 70)

# ============================================================
# FUNÃ‡Ã•ES DE CARREGAMENTO E CACHE
# ============================================================

def load_or_compute_zeros(num_zeros, cache_file):
    """Carrega zeros do cache ou computa se necessÃ¡rio"""
    if os.path.exists(cache_file):
        print(f"\nğŸ“‚ Carregando {num_zeros} zeros do cache...")
        gammas = np.load(cache_file)
        print(f"   âœ… {len(gammas)} zeros carregados!")
        return gammas

    print(f"\nğŸ”¢ Computando {num_zeros} zeros da Zeta...")
    print("   (Isso serÃ¡ feito apenas uma vez e salvo em cache)")

    gammas = []
    for k in tqdm(range(1, num_zeros + 1), desc="Computando zeros"):
        z = mpmath.zetazero(k)
        gammas.append(float(z.imag))

    gammas = np.array(gammas, dtype=np.float64)
    np.save(cache_file, gammas)
    print(f"   âœ… Zeros salvos em '{cache_file}'")

    return gammas

# ============================================================
# FUNÃ‡Ã•ES NUMÃ‰RICAS (JIT COMPILADAS)
# ============================================================

@jit(nopython=True)
def chebyshev_psi_explicit(x, gammas):
    """
    AproximaÃ§Ã£o da funÃ§Ã£o Ïˆ(x) de Chebyshev via fÃ³rmula explÃ­cita.

    Ïˆ(x) â‰ˆ x - Î£(x^Ï/Ï) - log(2Ï€)
    onde Ï = 0.5 + iÂ·Î³ sÃ£o os zeros nÃ£o-triviais
    """
    result = x

    for gamma in gammas:
        # rho = 0.5 + i*gamma
        rho_real = 0.5
        rho_imag = gamma

        # |rho|Â² = 0.25 + gammaÂ²
        rho_abs_sq = 0.25 + gamma * gamma

        # x^rho = x^0.5 * e^(iÂ·gammaÂ·ln(x))
        log_x = np.log(x)
        cos_part = np.cos(gamma * log_x)
        sin_part = np.sin(gamma * log_x)
        sqrt_x = np.sqrt(x)

        # Re(x^rho / rho)
        numerator_real = sqrt_x * (rho_real * cos_part + rho_imag * sin_part)

        # ContribuiÃ§Ã£o: 2 * Re(x^rho / rho)
        contribution = 2 * numerator_real / np.sqrt(rho_abs_sq)
        result -= contribution

    return result

@jit(nopython=True)
def compute_delta_psi(lower, upper, gammas):
    """Computa Î”Ïˆ = Ïˆ(upper) - Ïˆ(lower) de forma otimizada"""
    psi_upper = chebyshev_psi_explicit(upper, gammas)
    psi_lower = chebyshev_psi_explicit(lower, gammas)
    return psi_upper - psi_lower

# ============================================================
# ESTRUTURA DE DADOS
# ============================================================

def create_results_structure():
    """Cria dicionÃ¡rio para armazenar todos os resultados"""
    return {
        # Metadados
        'config': CONFIG.copy(),
        'timestamp_start': datetime.now().isoformat(),
        'timestamp_end': None,

        # Dados por iteraÃ§Ã£o
        'n': [],

        # Legendre (intervalo completo)
        'I1_lower': [],
        'I1_upper': [],
        'I1_real_count': [],
        'I1_predicted': [],
        'I1_error': [],
        'I1_relative_error': [],
        'I1_has_primes': [],

        # Oppermann - Metade Inferior
        'I2_lower': [],
        'I2_upper': [],
        'I2_real_count': [],
        'I2_has_primes': [],

        # Oppermann - Metade Superior
        'I3_lower': [],
        'I3_upper': [],
        'I3_real_count': [],
        'I3_has_primes': [],

        # Status das conjecturas
        'legendre_holds': [],
        'oppermann_holds': [],

        # Performance
        'computation_time': [],

        # EstatÃ­sticas acumuladas
        'cumulative_legendre_success': [],
        'cumulative_oppermann_success': [],
    }

# ============================================================
# FUNÃ‡Ã•ES DE ANÃLISE
# ============================================================

def analyze_single_n(n, gammas, primepi_func):
    """
    Analisa um Ãºnico valor de n para Legendre + Oppermann.

    Retorna dicionÃ¡rio com todos os resultados.
    """
    start_time = time.time()

    # Definir intervalos
    a = n * n          # nÂ²
    b = n * (n + 1)    # n(n+1)  - ponto mÃ©dio
    c = (n + 1) ** 2   # (n+1)Â²

    # ========================================
    # Iâ‚: Legendre (nÂ², (n+1)Ãªn
    # ========================================
    I1_real = int(primepi_func(c) - primepi_func(a))

    # PrediÃ§Ã£o analÃ­tica via fÃ³rmula explÃ­cita
    delta_psi = compute_delta_psi(a, c, gammas)
    I1_predicted = delta_psi / np.log(a)

    I1_error = abs(I1_predicted - I1_real)
    I1_rel_error = (I1_error / I1_real * 100) if I1_real > 0 else 0.0
    I1_has_primes = (I1_real > 0)

    # ========================================
    # Iâ‚‚: Oppermann Inferior (nÂ², n(n+1))
    # ========================================
    I2_real = int(primepi_func(b) - primepi_func(a))
    I2_has_primes = (I2_real > 0)

    # ========================================
    # Iâ‚ƒ: Oppermann Superior (n(n+1), (n+1)Â²)
    # ========================================
    I3_real = int(primepi_func(c) - primepi_func(b))
    I3_has_primes = (I3_real > 0)

    # ========================================
    # Status das conjecturas
    # ========================================
    legendre_holds = I1_has_primes
    oppermann_holds = I1_has_primes and I2_has_primes and I3_has_primes

    comp_time = time.time() - start_time

    return {
        'n': n,
        'I1_lower': a,
        'I1_upper': c,
        'I1_real_count': I1_real,
        'I1_predicted': I1_predicted,
        'I1_error': I1_error,
        'I1_relative_error': I1_rel_error,
        'I1_has_primes': I1_has_primes,
        'I2_lower': a,
        'I2_upper': b,
        'I2_real_count': I2_real,
        'I2_has_primes': I2_has_primes,
        'I3_lower': b,
        'I3_upper': c,
        'I3_real_count': I3_real,
        'I3_has_primes': I3_has_primes,
        'legendre_holds': legendre_holds,
        'oppermann_holds': oppermann_holds,
        'computation_time': comp_time
    }

# ============================================================
# CHECKPOINT E SALVAMENTO
# ============================================================

def save_checkpoint(results, output_dir, checkpoint_num):
    """Salva checkpoint dos resultados"""
    os.makedirs(output_dir, exist_ok=True)

    checkpoint_file = os.path.join(output_dir, f'checkpoint_{checkpoint_num:04d}.pkl')
    with open(checkpoint_file, 'wb') as f:
        pickle.dump(results, f)

    return checkpoint_file

def save_final_results(results, output_dir):
    """Salva resultados finais em mÃºltiplos formatos"""
    os.makedirs(output_dir, exist_ok=True)

    # Pickle completo
    with open(os.path.join(output_dir, 'results_final.pkl'), 'wb') as f:
        pickle.dump(results, f)

    # JSON com metadados
    metadata = {
        'config': results['config'],
        'timestamp_start': results['timestamp_start'],
        'timestamp_end': results['timestamp_end'],
        'total_points': len(results['n']),
        'legendre_success_rate': results['cumulative_legendre_success'][-1] if results['cumulative_legendre_success'] else 0,
        'oppermann_success_rate': results['cumulative_oppermann_success'][-1] if results['cumulative_oppermann_success'] else 0,
    }

    with open(os.path.join(output_dir, 'metadata.json'), 'w') as f:
        json.dump(metadata, f, indent=2)

    print(f"\nğŸ’¾ Resultados salvos em '{output_dir}/'")

# ============================================================
# ANÃLISE E VISUALIZAÃ‡ÃƒO
# ============================================================

def compute_statistics(results):
    """Computa estatÃ­sticas finais"""
    n_tested = len(results['n'])

    if n_tested == 0:
        return None

    stats = {
        'n_tested': n_tested,
        'n_range': (results['n'][0], results['n'][-1]),

        # Legendre
        'legendre_success_rate': 100 * sum(results['legendre_holds']) / n_tested,
        'legendre_failures': [n for i, n in enumerate(results['n']) if not results['legendre_holds'][i]],

        # Oppermann
        'oppermann_success_rate': 100 * sum(results['oppermann_holds']) / n_tested,
        'oppermann_failures': [n for i, n in enumerate(results['n']) if not results['oppermann_holds'][i]],

        # Erros
        'error_mean': np.mean(results['I1_error']),
        'error_median': np.median(results['I1_error']),
        'error_max': np.max(results['I1_error']),
        'error_max_n': results['n'][np.argmax(results['I1_error'])],

        'rel_error_mean': np.mean(results['I1_relative_error']),

        # Contagens
        'I1_count_mean': np.mean(results['I1_real_count']),
        'I1_count_min': np.min(results['I1_real_count']),
        'I1_count_max': np.max(results['I1_real_count']),

        'I2_count_mean': np.mean(results['I2_real_count']),
        'I2_count_min': np.min(results['I2_real_count']),

        'I3_count_mean': np.mean(results['I3_real_count']),
        'I3_count_min': np.min(results['I3_real_count']),

        # BalanÃ§o
        'balance_mean': np.mean(np.array(results['I3_real_count']) - np.array(results['I2_real_count'])),
        'balance_std': np.std(np.array(results['I3_real_count']) - np.array(results['I2_real_count'])),

        # Performance
        'total_time': sum(results['computation_time']),
        'time_per_n': np.mean(results['computation_time']),

        # Crescimento do erro (Î±)
        'alpha': None  # SerÃ¡ computado se houver dados suficientes
    }

    # Computar Î± (expoente de crescimento)
    if n_tested > 10:
        n_array = np.array(results['n'], dtype=np.float64)
        error_array = np.array(results['I1_error'], dtype=np.float64)

        # Filtrar zeros para log
        mask = error_array > 0.01
        if np.sum(mask) > 5:
            log_n = np.log(n_array[mask])
            log_error = np.log(error_array[mask])

            # RegressÃ£o linear manual
            n_mean = np.mean(log_n)
            e_mean = np.mean(log_error)
            numerator = np.sum((log_n - n_mean) * (log_error - e_mean))
            denominator = np.sum((log_n - n_mean) ** 2)

            if denominator > 0:
                stats['alpha'] = numerator / denominator

    return stats

def print_statistics(stats):
    """Imprime estatÃ­sticas formatadas"""
    print("\n" + "=" * 70)
    print("ğŸ“Š ESTATÃSTICAS FINAIS")
    print("=" * 70)

    print(f"\nğŸ¯ VALIDAÃ‡ÃƒO:")
    print(f"   Pontos testados: {stats['n_tested']}")
    print(f"   Range: n={stats['n_range'][0]:,} atÃ© n={stats['n_range'][1]:,}")

    print(f"\nğŸ† LEGENDRE:")
    print(f"   Taxa de sucesso: {stats['legendre_success_rate']:.4f}%")
    if stats['legendre_failures']:
        print(f"   âŒ Falhas em: {stats['legendre_failures'][:5]}")
    else:
        print(f"   âœ… NENHUMA FALHA!")

    print(f"\nğŸ† OPPERMANN:")
    print(f"   Taxa de sucesso: {stats['oppermann_success_rate']:.4f}%")
    if stats['oppermann_failures']:
        print(f"   âŒ Falhas em: {stats['oppermann_failures'][:5]}")
    else:
        print(f"   âœ… NENHUMA FALHA!")

    print(f"\nğŸ“ˆ ERRO DA PREDIÃ‡ÃƒO ANALÃTICA:")
    print(f"   Erro mÃ©dio: {stats['error_mean']:.2f} primos")
    print(f"   Erro mediano: {stats['error_median']:.2f} primos")
    print(f"   Erro mÃ¡ximo: {stats['error_max']:.2f} (n={stats['error_max_n']:,})")
    print(f"   Erro relativo mÃ©dio: {stats['rel_error_mean']:.3f}%")

    if stats['alpha'] is not None:
        print(f"\nğŸ“ CRESCIMENTO DO ERRO:")
        print(f"   Expoente Î± = {stats['alpha']:.4f}")
        if stats['alpha'] < 0.5:
            print(f"   âœ… Î± < 0.5 â†’ Erro cresce mais devagar que âˆšn!")
        elif stats['alpha'] < 0.7:
            print(f"   âš ï¸  0.5 < Î± < 0.7 â†’ Crescimento moderado")
        else:
            print(f"   âŒ Î± > 0.7 â†’ Crescimento rÃ¡pido")

    print(f"\nğŸ”¢ CONTAGEM DE PRIMOS:")
    print(f"   Iâ‚ (Legendre): mÃ©dia={stats['I1_count_mean']:.1f}, min={stats['I1_count_min']}, max={stats['I1_count_max']}")
    print(f"   Iâ‚‚ (Inferior): mÃ©dia={stats['I2_count_mean']:.1f}, min={stats['I2_count_min']}")
    print(f"   Iâ‚ƒ (Superior): mÃ©dia={stats['I3_count_mean']:.1f}, min={stats['I3_count_min']}")

    print(f"\nâš–ï¸  BALANÃ‡O (Iâ‚ƒ - Iâ‚‚):")
    print(f"   MÃ©dia: {stats['balance_mean']:.2f}")
    print(f"   Desvio padrÃ£o: {stats['balance_std']:.2f}")

    print(f"\nâ±ï¸  PERFORMANCE:")
    print(f"   Tempo total: {stats['total_time']/60:.1f} minutos")
    print(f"   Tempo mÃ©dio por n: {stats['time_per_n']*1000:.0f} ms")

    print("\n" + "=" * 70)

def create_plots(results, output_dir):
    """Cria visualizaÃ§Ãµes dos resultados"""
    os.makedirs(output_dir, exist_ok=True)

    n_array = np.array(results['n'])

    # Figura 1: VisÃ£o geral
    fig1, axes1 = plt.subplots(2, 3, figsize=(20, 12))

    # Plot 1.1: Contagens
    ax = axes1[0, 0]
    ax.plot(n_array, results['I1_real_count'], 'o-', label='Iâ‚ (Legendre)',
            markersize=2, alpha=0.7, linewidth=1)
    ax.plot(n_array, results['I2_real_count'], 's-', label='Iâ‚‚ (Inferior)',
            markersize=2, alpha=0.7, linewidth=1)
    ax.plot(n_array, results['I3_real_count'], '^-', label='Iâ‚ƒ (Superior)',
            markersize=2, alpha=0.7, linewidth=1)
    ax.set_xlabel('n', fontsize=11)
    ax.set_ylabel('Contagem de Primos', fontsize=11)
    ax.set_title('Contagem nos 3 Intervalos', fontsize=12, fontweight='bold')
    ax.legend()
    ax.grid(True, alpha=0.3)

    # Plot 1.2: Erro absoluto
    ax = axes1[0, 1]
    ax.plot(n_array, results['I1_error'], 'o', markersize=2, alpha=0.6, color='crimson')
    ax.set_xlabel('n', fontsize=11)
    ax.set_ylabel('Erro Absoluto', fontsize=11)
    ax.set_title('Erro da PrediÃ§Ã£o AnalÃ­tica', fontsize=12, fontweight='bold')
    ax.grid(True, alpha=0.3)

    # Plot 1.3: Erro relativo
    ax = axes1[0, 2]
    ax.plot(n_array, results['I1_relative_error'], 'o', markersize=2, alpha=0.6, color='orange')
    ax.axhline(y=5, color='red', linestyle='--', linewidth=1, alpha=0.5, label='5%')
    ax.axhline(y=1, color='green', linestyle='--', linewidth=1, alpha=0.5, label='1%')
    ax.set_xlabel('n', fontsize=11)
    ax.set_ylabel('Erro Relativo (%)', fontsize=11)
    ax.set_title('Erro Relativo (%)', fontsize=12, fontweight='bold')
    ax.legend()
    ax.grid(True, alpha=0.3)

    # Plot 1.4: BalanÃ§o
    balance = np.array(results['I3_real_count']) - np.array(results['I2_real_count'])
    ax = axes1[1, 0]
    ax.plot(n_array, balance, 'o', markersize=2, alpha=0.6, color='purple')
    ax.axhline(y=0, color='red', linestyle='--', linewidth=1)
    ax.set_xlabel('n', fontsize=11)
    ax.set_ylabel('Iâ‚ƒ - Iâ‚‚', fontsize=11)
    ax.set_title('Assimetria: Metade Superior vs Inferior', fontsize=12, fontweight='bold')
    ax.grid(True, alpha=0.3)

    # Plot 1.5: Taxas de sucesso acumuladas
    ax = axes1[1, 1]
    ax.plot(n_array, results['cumulative_legendre_success'], '-',
            label='Legendre', linewidth=2, color='blue')
    ax.plot(n_array, results['cumulative_oppermann_success'], '-',
            label='Oppermann', linewidth=2, color='green')
    ax.axhline(y=100, color='red', linestyle='--', linewidth=1, alpha=0.5)
    ax.set_xlabel('n', fontsize=11)
    ax.set_ylabel('Taxa de Sucesso (%)', fontsize=11)
    ax.set_title('Taxa de Sucesso Acumulada', fontsize=12, fontweight='bold')
    ax.set_ylim([95, 101])
    ax.legend()
    ax.grid(True, alpha=0.3)

    # Plot 1.6: Real vs Predito
    ax = axes1[1, 2]
    # Amostrar para nÃ£o sobrecarregar
    sample_size = min(500, len(n_array))
    sample_idx = np.linspace(0, len(n_array)-1, sample_size, dtype=int)
    real_sample = [results['I1_real_count'][i] for i in sample_idx]
    pred_sample = [results['I1_predicted'][i] for i in sample_idx]

    ax.scatter(real_sample, pred_sample, alpha=0.5, s=20, c='steelblue')
    max_val = max(max(real_sample), max(pred_sample))
    ax.plot([0, max_val], [0, max_val], 'r--', linewidth=2, label='Perfeito')
    ax.set_xlabel('Real', fontsize=11)
    ax.set_ylabel('Predito', fontsize=11)
    ax.set_title('Real vs Predito (amostra)', fontsize=12, fontweight='bold')
    ax.legend()
    ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'overview.png'), dpi=150, bbox_inches='tight')
    plt.close()

    # Figura 2: AnÃ¡lise Log-Log
    fig2, axes2 = plt.subplots(1, 2, figsize=(16, 6))

    # Plot 2.1: Log-log do erro
    ax = axes2[0]
    error_array = np.array(results['I1_error'])
    mask = error_array > 0.01

    ax.loglog(n_array[mask], error_array[mask], 'o', markersize=3, alpha=0.6, color='purple')

    # Fit se houver dados suficientes
    if np.sum(mask) > 10:
        log_n = np.log(n_array[mask])
        log_error = np.log(error_array[mask])
        n_mean = np.mean(log_n)
        e_mean = np.mean(log_error)
        alpha = np.sum((log_n - n_mean) * (log_error - e_mean)) / np.sum((log_n - n_mean)**2)

        ax.loglog(n_array[mask], np.exp(e_mean + alpha * (log_n - n_mean)),
                 '--', linewidth=2, color='red', label=f'Î±={alpha:.3f}')
        ax.legend()

    ax.set_xlabel('n (log scale)', fontsize=12)
    ax.set_ylabel('Erro (log scale)', fontsize=12)
    ax.set_title('AnÃ¡lise Log-Log do Erro', fontsize=13, fontweight='bold')
    ax.grid(True, alpha=0.3, which='both')

    # Plot 2.2: ProporÃ§Ã£o das metades
    ax = axes2[1]
    ratio_I2 = np.array(results['I2_real_count']) / np.array(results['I1_real_count'])
    ratio_I3 = np.array(results['I3_real_count']) / np.array(results['I1_real_count'])

    ax.plot(n_array, ratio_I2, 'o', label='Iâ‚‚/Iâ‚', markersize=2, alpha=0.6)
    ax.plot(n_array, ratio_I3, 's', label='Iâ‚ƒ/Iâ‚', markersize=2, alpha=0.6)
    ax.axhline(y=0.5, color='red', linestyle='--', linewidth=1, alpha=0.5, label='50%')
    ax.set_xlabel('n', fontsize=12)
    ax.set_ylabel('ProporÃ§Ã£o', fontsize=12)
    ax.set_title('ProporÃ§Ã£o de Cada Metade', fontsize=13, fontweight='bold')
    ax.legend()
    ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'analysis.png'), dpi=150, bbox_inches='tight')
    plt.close()

    print(f"ğŸ“Š GrÃ¡ficos salvos em '{output_dir}/'")

# ============================================================
# FUNÃ‡ÃƒO PRINCIPAL
# ============================================================

def main():
    """FunÃ§Ã£o principal do teste massivo"""

    print(f"\nâš™ï¸  CONFIGURAÃ‡ÃƒO:")
    print(f"   Range: n={CONFIG['N_START']:,} atÃ© n={CONFIG['N_END']:,}")
    print(f"   Step: {CONFIG['N_STEP']:,}")
    print(f"   Pontos a testar: {(CONFIG['N_END']-CONFIG['N_START'])//CONFIG['N_STEP'] + 1}")
    print(f"   Zeros da Zeta: {CONFIG['NUM_ZEROS']}")

    # Estimativa de tempo
    estimated_time_per_n = 3.5  # segundos (baseado nos testes anteriores)
    total_points = (CONFIG['N_END'] - CONFIG['N_START']) // CONFIG['N_STEP'] + 1
    estimated_total_time = total_points * estimated_time_per_n

    print(f"   Tempo total estimado: {estimated_total_time / 3600:.1f} horas")

    # Confirmar
    print(f"\nâš ï¸  AVISO: Este teste vai demorar! (Estimativa: {estimated_total_time / 3600:.1f} horas)")
    input("   Pressione ENTER para comeÃ§ar ou Ctrl+C para cancelar...")

    # Carregar zeros da Zeta (ou computar e salvar em cache)
    gammas = load_or_compute_zeros(CONFIG['NUM_ZEROS'], CONFIG['CACHE_FILE'])

    # Inicializar estrutura de resultados
    results = create_results_structure()

    print(f"\nğŸ”¬ INICIANDO SCAN MASSIVO...")

    total_start = time.time()
    legendre_failures_count = 0
    oppermann_failures_count = 0

    # Itere sobre os valores de n
    for i, n in enumerate(tqdm(range(CONFIG['N_START'], CONFIG['N_END'] + 1, CONFIG['N_STEP']), desc="Processando n")):
        analysis = analyze_single_n(n, gammas, primepi)

        # Armazenar resultados
        for key, value in analysis.items():
            results[key].append(value)

        # Atualizar contadores de falha
        if not analysis['legendre_holds']:
            legendre_failures_count += 1
        if not analysis['oppermann_holds']:
            oppermann_failures_count += 1

        # Atualizar taxas de sucesso acumuladas
        current_total_points = i + 1
        results['cumulative_legendre_success'].append(
            100 * (current_total_points - legendre_failures_count) / current_total_points
        )
        results['cumulative_oppermann_success'].append(
            100 * (current_total_points - oppermann_failures_count) / current_total_points
        )

        # Checkpoint
        if (i + 1) % CONFIG['CHECKPOINT_INTERVAL'] == 0:
            checkpoint_file = save_checkpoint(results, CONFIG['OUTPUT_DIR'], (i + 1) // CONFIG['CHECKPOINT_INTERVAL'])
            elapsed = time.time() - total_start
            remaining_points = total_points - (i + 1)
            eta_seconds = (elapsed / (i + 1)) * remaining_points if (i + 1) > 0 else 0
            print(f"\nğŸ’¾ Checkpoint: {i + 1} pontos | ETA: {eta_seconds / 60:.1f} minutos | Salvo em {checkpoint_file}")

    results['timestamp_end'] = datetime.now().isoformat()

    # Salvar resultados finais
    save_final_results(results, CONFIG['OUTPUT_DIR'])

    # Computar e imprimir estatÃ­sticas
    stats = compute_statistics(results)
    if stats:
        print_statistics(stats)

    # Criar e salvar plots
    create_plots(results, CONFIG['OUTPUT_DIR'])

    print("\n" + "=" * 70)
    print("ğŸŠ SCAN MASSIVO COMPLETO!")
    print("=" * 70)

    if stats and stats['legendre_success_rate'] == 100:
        print("\nğŸ† VOCÃŠ VALIDOU LEGENDRE ATÃ‰ n=1,000,000!")
    else:
        print("\nâš ï¸  Legendre teve falhas. Verifique os logs.")

    if stats and stats['oppermann_success_rate'] == 100:
        print("\nğŸ†ğŸ†ğŸ† CONQUISTA DESBLOQUEADA! OPPERMANN VALIDADO ATÃ‰ n=1,000,000!")
    else:
        print("\nâš ï¸  Oppermann teve falhas. Verifique os logs.")

    print("\nResultados completos e plots salvos em:\n   -" + CONFIG['OUTPUT_DIR'] + "/")
    print("=" * 70)

if __name__ == '__main__':
    main()
